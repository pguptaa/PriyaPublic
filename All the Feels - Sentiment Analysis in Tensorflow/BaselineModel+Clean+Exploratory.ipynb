{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priyagupta/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/priyagupta/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import HTMLParser as htm\n",
    "import string\n",
    "import re\n",
    "\n",
    "# SK-learn library for splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Positive</th>\n",
       "      <th>escape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138881940341260288:</td>\n",
       "      <td>I got a surprise for all you bitches...pull th...</td>\n",
       "      <td>:: surprise</td>\n",
       "      <td>0</td>\n",
       "      <td>I got a surprise for all you bitches...pull th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144479819843911683:</td>\n",
       "      <td>If I was a thief.. The first thing I would ste...</td>\n",
       "      <td>:: joy</td>\n",
       "      <td>1</td>\n",
       "      <td>If I was a thief.. The first thing I would ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139110849120972800:</td>\n",
       "      <td>\"&amp;quot;@RevRunWisdom: not afraid of tomorrow, ...</td>\n",
       "      <td>:: fear</td>\n",
       "      <td>0</td>\n",
       "      <td>\"\"@RevRunWisdom: not afraid of tomorrow, for I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141532076791971840:</td>\n",
       "      <td>\"Extreme can neither fight nor fly.&amp;#xA;-- Wil...</td>\n",
       "      <td>:: fear</td>\n",
       "      <td>0</td>\n",
       "      <td>\"Extreme can neither fight nor fly.\\n-- Willia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>145353048817012736:</td>\n",
       "      <td>Thinks that @melbahughes had a great 50th birt...</td>\n",
       "      <td>:: surprise</td>\n",
       "      <td>0</td>\n",
       "      <td>Thinks that @melbahughes had a great 50th birt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Id                                              Tweet  \\\n",
       "0  138881940341260288:  I got a surprise for all you bitches...pull th...   \n",
       "1  144479819843911683:  If I was a thief.. The first thing I would ste...   \n",
       "2  139110849120972800:  \"&quot;@RevRunWisdom: not afraid of tomorrow, ...   \n",
       "3  141532076791971840:  \"Extreme can neither fight nor fly.&#xA;-- Wil...   \n",
       "4  145353048817012736:  Thinks that @melbahughes had a great 50th birt...   \n",
       "\n",
       "       Emotion  Positive                                             escape  \n",
       "0  :: surprise         0  I got a surprise for all you bitches...pull th...  \n",
       "1       :: joy         1  If I was a thief.. The first thing I would ste...  \n",
       "2      :: fear         0  \"\"@RevRunWisdom: not afraid of tomorrow, for I...  \n",
       "3      :: fear         0  \"Extreme can neither fight nor fly.\\n-- Willia...  \n",
       "4  :: surprise         0  Thinks that @melbahughes had a great 50th birt...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"tweet_data_1.csv\",sep='\\t',quoting=3)\n",
    "data[\"escape\"] = data.apply(lambda row: htm.HTMLParser().unescape(row[1].decode(\"utf-8\")),axis=1)\n",
    "#data[\"escape\"] = data.apply(lambda row: row[3]*5)\n",
    " \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    \"\"\"Converts to lowercase, strips out punctuation,\n",
    "    removes excess whitespace within a string & leading & trailing whitespace\"\"\"\n",
    "    new_list = []\n",
    "    table = string.maketrans(\"\",\"\")\n",
    "    for elem in data:\n",
    "        elem = \"\".join(i for i in elem if ord(i)<128)\n",
    "        elem = str(elem)        \n",
    "        elem = elem.lower()\n",
    "        elem = elem.translate(table, string.punctuation)\n",
    "        \n",
    "        # Comment these 2 lines out to improve positive\n",
    "        elem = re.sub(' +',' ', elem)\n",
    "        elem = elem.strip()\n",
    "        \n",
    "        new_list.append(elem)\n",
    "    return new_list\n",
    "\n",
    "#train_pol_x = process_data(train_pol_x)\n",
    "#test_pol_x = process_data(test_pol_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into train & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#process entire data set\n",
    "data.escape = process_data(data.escape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train and test data frames\n",
    "train, test = train_test_split(data, test_size = 0.2)\n",
    "\n",
    "# Train and test target labels\n",
    "train_pol_y = train.ix[:,3].tolist()\n",
    "test_pol_y = test.ix[:,3].tolist()\n",
    "\n",
    "train_pol_x2 = train.ix[:,3:5]\n",
    "\n",
    "\n",
    "#binarize emo labels\n",
    "from sklearn import preprocessing\n",
    "train_emo = train.ix[:,2].tolist()\n",
    "test_emo = test.ix[:,2].tolist()\n",
    "\n",
    "emo_bin = preprocessing.LabelBinarizer()\n",
    "\n",
    "train_emo_y = emo_bin.fit_transform(train_emo)\n",
    "tests_emo_y = emo_bin.transform(test_emo)\n",
    "# To get emotionas use emo_bin.inverse_transform(tests_emo_y)\n",
    "\n",
    "# MC NEW CODE\n",
    "# Train and test x\n",
    "train_pol_x = train.ix[:, 4].tolist()\n",
    "test_pol_x = test.ix[:, 4].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory on entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 21051 \n",
      "\n",
      "Polarity counts\n",
      "0    12811\n",
      "1     8240\n",
      "Name: Positive, dtype: int64\n",
      "\n",
      "\n",
      "Avg Words 15.0530141086 \n",
      "\n",
      "Emotion Counts\n",
      ":: joy         8240\n",
      ":: surprise    3849\n",
      ":: sadness     3830\n",
      ":: fear        2816\n",
      ":: anger       1555\n",
      ":: disgust      761\n",
      "Name: Emotion, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print \"Dataset size: %s \\n\" % len(data)\n",
    "\n",
    "print \"Polarity counts\"\n",
    "print data.Positive.value_counts()\n",
    "print \"\\n\"\n",
    "#avg number of words\n",
    "\n",
    "print \"Avg Words %s \\n\" % np.mean([len(s.split(\" \")) for s in data.escape])\n",
    "print \"Emotion Counts\"\n",
    "print data.Emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#top words\n",
    "from collections import Counter\n",
    "holder = Counter()\n",
    "\n",
    "#process entire dataset\n",
    "data_ = data.ix[:, 4].tolist()\n",
    "process_data(data_)\n",
    "\n",
    "for i in data_:\n",
    "    for word in i.split(\" \"):\n",
    "        holder[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the \t 9098\n",
      "i \t 8867\n",
      "to \t 8101\n",
      "a \t 6230\n",
      "my \t 5487\n",
      "and \t 5395\n",
      "of \t 4776\n",
      "in \t 4169\n",
      "is \t 3780\n",
      "for \t 3539\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "for i in holder.most_common(10):\n",
    "    #if i[0].lower() not in stopwords.words(\"english\"):\n",
    "    print \"%s \\t %s\" % (i[0],i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With one Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   :: anger       0.55      0.29      0.38       320\n",
      " :: disgust       0.44      0.08      0.13       151\n",
      "    :: fear       0.73      0.50      0.60       582\n",
      "     :: joy       0.59      0.84      0.69      1639\n",
      " :: sadness       0.43      0.39      0.41       742\n",
      ":: surprise       0.57      0.46      0.51       777\n",
      "\n",
      "avg / total       0.57      0.58      0.55      4211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#with one model only\n",
    "vectorizer = TfidfVectorizer(min_df=2,\n",
    "                             use_idf=True,\n",
    "                            stop_words='english',\n",
    "                            )\n",
    "train_vectors = vectorizer.fit_transform(train_pol_x)\n",
    "test_vectors = vectorizer.transform(test_pol_x)\n",
    "\n",
    "base1 = svm.SVC(kernel='linear')\n",
    "base1.fit(train_vectors, train_emo)\n",
    "predict_base1 = base1.predict(test_vectors)\n",
    "\n",
    "print classification_report(test_emo,predict_base1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With 2 Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.78      0.85      0.81      2572\n",
      "   Positive       0.72      0.63      0.67      1639\n",
      "\n",
      "avg / total       0.76      0.76      0.76      4211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classifier 1\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#min_df_options = [1, 2, 5, 10, 25]\n",
    "\n",
    "#for df in min_df_options:\n",
    "#print \"Minimum DF\", df\n",
    "vectorizer = TfidfVectorizer(min_df=2,\n",
    "                             use_idf=True,\n",
    "                            stop_words='english',\n",
    "                            )\n",
    "train_vectors = vectorizer.fit_transform(train_pol_x)\n",
    "test_vectors = vectorizer.transform(test_pol_x)\n",
    "\n",
    "base1 = svm.SVC(kernel='linear')\n",
    "base1.fit(train_vectors, train_pol_y)\n",
    "predict_base1 = base1.predict(test_vectors)\n",
    "\n",
    "target_names = [\"Negative\",\"Positive\"]\n",
    "print classification_report(test_pol_y,predict_base1, target_names = target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'Positive': predict_base1.tolist() , 'escape': test_pol_x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pol_x2 = train.ix[:,3:5]\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "mapper = DataFrameMapper([\n",
    "        ([\"Positive\"],None),\n",
    "    (\"escape\",TfidfVectorizer(min_df=2,use_idf=True,stop_words='english'))])\n",
    "\n",
    "train_m2 = mapper.fit_transform(train_pol_x2,train_emo)\n",
    "test_m2 = mapper.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   :: anger       0.57      0.25      0.35       320\n",
      " :: disgust       0.58      0.05      0.09       151\n",
      "    :: fear       0.66      0.53      0.59       582\n",
      "     :: joy       0.72      0.63      0.67      1639\n",
      " :: sadness       0.36      0.57      0.44       742\n",
      ":: surprise       0.46      0.58      0.51       777\n",
      "\n",
      "avg / total       0.58      0.55      0.55      4211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log = LogisticRegression()\n",
    "\n",
    "log.fit(train_m2,train_emo)\n",
    "preds = log.predict(test_m2)\n",
    "\n",
    "print classification_report(test_emo,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#base2 = svm.SVC(kernel='linear')\n",
    "#base2.fit(train_m2,train_emo)\n",
    "#predict_base2 = base2.predict(test_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print classification_report(test_emo,predict_base2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model without preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try different hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCENT: ascii\n",
      "LOWERCASE OPTION: True\n",
      "Minimum DF: 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.78      0.86      0.82      2538\n",
      "   Positive       0.75      0.64      0.69      1673\n",
      "\n",
      "avg / total       0.77      0.77      0.77      4211\n",
      "\n",
      "Minimum DF: 2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.78      0.86      0.82      2538\n",
      "   Positive       0.75      0.63      0.69      1673\n",
      "\n",
      "avg / total       0.77      0.77      0.76      4211\n",
      "\n",
      "Minimum DF: 5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.77      0.86      0.81      2538\n",
      "   Positive       0.74      0.62      0.68      1673\n",
      "\n",
      "avg / total       0.76      0.76      0.76      4211\n",
      "\n",
      "LOWERCASE OPTION: False\n",
      "Minimum DF: 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.79      0.85      0.82      2538\n",
      "   Positive       0.75      0.66      0.70      1673\n",
      "\n",
      "avg / total       0.77      0.77      0.77      4211\n",
      "\n",
      "Minimum DF: 2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.78      0.85      0.82      2538\n",
      "   Positive       0.74      0.64      0.69      1673\n",
      "\n",
      "avg / total       0.77      0.77      0.77      4211\n",
      "\n",
      "Minimum DF: 5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.77      0.85      0.81      2538\n",
      "   Positive       0.74      0.62      0.67      1673\n",
      "\n",
      "avg / total       0.76      0.76      0.76      4211\n",
      "\n",
      "ACCENT: unicode\n",
      "LOWERCASE OPTION: True\n",
      "Minimum DF: 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.79      0.85      0.82      2538\n",
      "   Positive       0.74      0.65      0.69      1673\n",
      "\n",
      "avg / total       0.77      0.77      0.77      4211\n",
      "\n",
      "Minimum DF: 2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.78      0.86      0.82      2538\n",
      "   Positive       0.74      0.64      0.69      1673\n",
      "\n",
      "avg / total       0.77      0.77      0.76      4211\n",
      "\n",
      "Minimum DF: 5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.77      0.86      0.81      2538\n",
      "   Positive       0.74      0.62      0.68      1673\n",
      "\n",
      "avg / total       0.76      0.76      0.76      4211\n",
      "\n",
      "LOWERCASE OPTION: False\n",
      "Minimum DF: 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.79      0.85      0.82      2538\n",
      "   Positive       0.75      0.66      0.70      1673\n",
      "\n",
      "avg / total       0.77      0.77      0.77      4211\n",
      "\n",
      "Minimum DF: 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-75c134b5fbf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mbase1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mbase1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pol_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mpredict_base1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_sparse_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                 \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshrinking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m                 random_seed)\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/svm/libsvm_sparse.pyx\u001b[0m in \u001b[0;36msklearn.svm.libsvm_sparse.libsvm_sparse_train (sklearn/svm/libsvm_sparse.c:2784)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/scipy/sparse/compressed.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;34m\"\"\"base matrix class for compressed row and column oriented matrices\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0m_data_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#https://marcobonzanini.com/2015/01/19/sentiment-analysis-with-python-and-scikit-learn/\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "min_df_options = [1, 2, 5]\n",
    "strip_accents_options = ['ascii', 'unicode']\n",
    "lowercase_options = [True, False]\n",
    "\n",
    "for elem in strip_accents_options:\n",
    "    print \"ACCENT:\", elem\n",
    "    for op in lowercase_options:\n",
    "        print \"LOWERCASE OPTION:\", str(op)\n",
    "        for df in min_df_options:\n",
    "            print \"Minimum DF:\", df\n",
    "            vectorizer = TfidfVectorizer(min_df=df,\n",
    "                                         use_idf=True,\n",
    "                                        stop_words='english',\n",
    "                                         strip_accents=elem,\n",
    "                                         lowercase=op\n",
    "                                        )\n",
    "            train_vectors = vectorizer.fit_transform(train.ix[:,4].tolist())\n",
    "            test_vectors = vectorizer.transform(test.ix[:,4].tolist())\n",
    "\n",
    "            base1 = svm.SVC(kernel='linear')\n",
    "            base1.fit(train_vectors, train_pol_y)\n",
    "            predict_base1 = base1.predict(test_vectors)\n",
    "\n",
    "            target_names = [\"Negative\",\"Positive\"]\n",
    "            print classification_report(test_pol_y,predict_base1, target_names = target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=2,\n",
    "                             use_idf=True,\n",
    "                             stop_words='english')\n",
    "train_vectors = vectorizer.fit_transform(train.ix[:,4].tolist())\n",
    "test_vectors = vectorizer.transform(test.ix[:,4].tolist())\n",
    "\n",
    "base1 = svm.SVC(kernel='linear')\n",
    "base1.fit(train_vectors, train_pol_y)\n",
    "predict_base1 = base1.predict(test_vectors)\n",
    "\n",
    "target_names = [\"Negative\",\"Positive\"]\n",
    "print classification_report(test_pol_y,predict_base1, target_names = target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=2,\n",
    "                             use_idf=True,\n",
    "                             stop_words='english')\n",
    "train_vectors = vectorizer.fit_transform(train.ix[:,4].tolist())\n",
    "test_vectors = vectorizer.transform(test.ix[:,4].tolist())\n",
    "\n",
    "base1 = svm.LinearSVC()\n",
    "\n",
    "C_options = {'C': np.arange(0.1, 1, 0.1)}\n",
    "grid = GridSearchCV(base1, C_options)\n",
    "\n",
    "grid.fit(train_vectors, train_pol_y)\n",
    "preds = grid.predict(test_vectors)\n",
    "    \n",
    "# Output best param\n",
    "print \"Best value for C: %.2f\" %grid.best_params_['C']\n",
    "print \"F1 score for Logistic Regression: %.3f\" %metrics.f1_score(test_pol_y, preds, average=\"weighted\") + \"\\n\"\n",
    "\n",
    "\n",
    "target_names = [\"Negative\",\"Positive\"]\n",
    "print classification_report(test_pol_y, preds, target_names = target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def P3(train_data, train_labels, dev_data, dev_labels):\n",
    "### STUDENT START ###\n",
    "\n",
    "    # Data setup\n",
    "    vec = TfidfVectorizer(min_df=2,\n",
    "                             use_idf=True,\n",
    "                             stop_words='english')\n",
    "    train_mat = vec.fit_transform(train_data)    \n",
    "    dev_fit = vec.transform(dev_data)\n",
    "    \n",
    "    # K-NN MODEL\n",
    "#     knn = KNeighborsClassifier()\n",
    "    \n",
    "    # Use GridSearchCV to find optimal k value\n",
    "#     k_options = {'n_neighbors':[i for i in range(1, 3)]}\n",
    "#     knn_grid = GridSearchCV(knn, k_options)\n",
    "\n",
    "#     knn_grid.fit(train_mat, train_labels)\n",
    "#     preds = knn_grid.predict(dev_fit)\n",
    "    \n",
    "    # Output best param\n",
    "#     print \"Best value for k: %d\" %knn_grid.best_params_['n_neighbors']\n",
    "#     print \"F1 score for K-NN: %.3f\" %metrics.f1_score(dev_labels, preds, average=\"weighted\") + \"\\n\"\n",
    "    \n",
    "    # MULTINOMIAL NAIVE BAYES\n",
    "    # Repeat process for multinomial Naive Bayes\n",
    "    mul = MultinomialNB(alpha=0.5)\n",
    "    \n",
    "    alpha_options = {'alpha': np.arange(0.01, 1, 0.01)}\n",
    "    mul_grid = GridSearchCV(mul, alpha_options)\n",
    "    \n",
    "    mul_grid.fit(train_mat, train_labels)\n",
    "    mul_preds = mul_grid.predict(dev_fit)\n",
    "    \n",
    "    # Output best param\n",
    "    print \"Best value for alpha: %.2f\" %mul_grid.best_params_['alpha']\n",
    "    print \"F1 score for Multinomial Naive Bayes: %.3f\" %metrics.f1_score(dev_labels, mul_preds, average=\"weighted\") + \"\\n\"\n",
    "\n",
    "    \n",
    "    # LOGISTIC REGRESSION\n",
    "    # Repeat process for multinomial Naive Bayes\n",
    "    log = LogisticRegression()\n",
    "#     log = LogisticRegression(class_weight='balanced')\n",
    "    \n",
    "    C_options = {'C': np.arange(0.1, 1, 0.1)}\n",
    "    log_grid = GridSearchCV(log, C_options)\n",
    "\n",
    "    log_grid.fit(train_mat, train_labels)\n",
    "    log_preds = log_grid.predict(dev_fit)\n",
    "    \n",
    "    # Output best param\n",
    "    print \"Best value for C: %.2f\" %log_grid.best_params_['C']\n",
    "    print \"F1 score for Logistic Regression: %.3f\" %metrics.f1_score(dev_labels, log_preds, average=\"weighted\") + \"\\n\"\n",
    "    \n",
    "    # Output sum of squared weights for a series of values of C\n",
    "#     C_vals = np.arange(0.1, 1, 0.1)\n",
    "#     for val in C_vals:\n",
    "#         log_mod = LogisticRegression(C=val)\n",
    "#         log_mod.fit(train_mat, train_labels)\n",
    "#         print \"Sum of squared weights for C=%.2f:\" %val, np.square(log_mod.coef_).sum(axis=1)\n",
    "    \n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "P3(train_pol_x, train_pol_y, test_pol_x, test_pol_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
